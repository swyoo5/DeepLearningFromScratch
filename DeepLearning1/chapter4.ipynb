{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54866319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2를 정답으로 추정했을 때 SSE :  0.09750000000000003\n",
      "7를 정답으로 추정했을 때 SSE :  0.5975\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_squares_error(y, t) : # 파라미터들은 넘파이배열\n",
    "    return 0.5 * np.sum((y - t) ** 2)\n",
    "\n",
    "# 차례대로 0 ~ 9에 해당하는 정답과 예측확률\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(\"2를 정답으로 추정했을 때 SSE : \", sum_squares_error(np.array(y), np.array(t)))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(\"7를 정답으로 추정했을 때 SSE : \" ,sum_squares_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f12d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2를 정답으로 예측했을 때 크로스엔트로피 :  0.510825457099338\n",
      "7를 정답으로 예측했을 때 크로스엔트로피 :  2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_error(y, t) :\n",
    "    delta = 1e-7 # log 0이 되는것을 방지하기 위해 아주 작은 값을 더해준다.\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(\"2를 정답으로 예측했을 때 크로스엔트로피 : \", cross_entropy_error(np.array(y), np.array(t)))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(\"7를 정답으로 예측했을 때 크로스엔트로피 : \",  cross_entropy_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b03fb64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "print(x_train.shape) # 훈련데이터\n",
    "print(t_train.shape) # 정답레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edc530d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니배치 학습\n",
    "train_size = x_train.shape[0] # 60000개의 데이터 훈련\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # [0 ~ 59999] 숫자 중 10개의 숫자 뽑아냄(10개의 인덱스 추출)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c7d5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치용 크로스엔트로피 구현\n",
    "def cross_entropy_error(y, t) :\n",
    "    if y.ndim == 1 :\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "812690e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치용 크로스엔트로피 구현(정답레이블이 확률이 아닌 숫자로 주어졌을 때)\n",
    "def cross_entropy_error(y, t) :\n",
    "    if y.ndim == 1 :\n",
    "        y = y.reshape(1, y.size)\n",
    "        t = y.reshape(1, t.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85404fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x) :\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "def function_1(x) :\n",
    "    return 0.01 * x ** 2 + 0.1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f07892e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b12a8578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_1, 5))\n",
    "print(numerical_diff(function_1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "969c8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x) :\n",
    "    return x[0] ** 2 + x[1] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6a5a5901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 편미분\n",
    "def temp_func1(x1) :\n",
    "    return x1 ** 2 + 4.0 ** 2.0\n",
    "\n",
    "numerical_diff(temp_func1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5ad2611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temp_func2(x2) :\n",
    "    return 3.0 ** 2.0 + x2 ** 2\n",
    "\n",
    "numerical_diff(temp_func2, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f3ec5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 구하기\n",
    "def numerical_gradient(f, x) :\n",
    "    h = 1e-4\n",
    "    gradient = np.zeros_like(x)\n",
    "    \n",
    "    for index in range(x.size) :\n",
    "        temp_val = x[index]\n",
    "        \n",
    "        x[index] = temp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[index] = temp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        gradient[index] = (fxh1 - fxh2) / (2 * h)\n",
    "        x[index] = temp_val\n",
    "        \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6e0715ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[0. 4.]\n",
      "[6. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
    "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
    "print(numerical_gradient(function_2, np.array([3.0, 0.0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1d75d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사하강법\n",
    "def gradient_descent(f, x_init, lr = 0.01, step_num = 100) :\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num) :\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e58b5694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x) :\n",
    "    return x[0] ** 2 + x[1] ** 2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x, lr = 0.1, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f5202751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet :\n",
    "    def __init__(self) :\n",
    "        self.W = np.random.randn(2, 3) # 사이즈 2, 3인 표준정규분포\n",
    "        \n",
    "    def predict(self, x) :\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t) :\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9770686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23059175  0.95601121 -0.68601935]\n",
      " [-0.16853557  0.99832202  0.55042515]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "859dff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01332696  1.47209654  0.08377102]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d3d3ea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cb45bcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7775923317137294"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b266f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09204137  0.4065316  -0.49857297]\n",
      " [ 0.13806206  0.6097974  -0.74785945]]\n"
     ]
    }
   ],
   "source": [
    "def f(W) :\n",
    "    return net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)\n",
    "\n",
    "# f = lambda x : net.loss(x, t)\n",
    "# dW = numerical_gradient(f, net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1a4ff523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2층 신경망 클래스 구현하기\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet :\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 weight_init_std = 0.01) :\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x) :\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x : 입력데이터, t : 정답레이블\n",
    "    def loss(self, x, t) :\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t) :\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        t = np.argmax(t, axis = 1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t) :\n",
    "        loss_W = lambda W : self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "61c826dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test)  = \\\n",
    "    load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
    "\n",
    "for i in range(iters_num) :\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2') :\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test)  = \\\n",
    "    load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "\n",
    "\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num) :\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2') :\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에촉당 정확도 계산\n",
    "    if i % iter_per_epoch == 0 :\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \"\n",
    "              + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a87032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
